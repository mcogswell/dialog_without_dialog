{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.questioner\n",
    "import models.answerer\n",
    "\n",
    "import misc.utilities as utils\n",
    "import misc.dataloader\n",
    "\n",
    "import misc.visualization as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(key, fname=None, epoch=60, agent='qbot', override=None):\n",
    "    global params\n",
    "    assert agent in ['abot', 'qbot']\n",
    "    if fname is None:\n",
    "        fname = 'data/experiments/{}/{}_ep_{}.vd'.format(key, agent, epoch)\n",
    "        print(fname)\n",
    "\n",
    "    bot = misc.utilities.loadModelFromFile(fname, agent=agent)\n",
    "    bot.eval()\n",
    "    if isinstance(bot, models.questioner.Questioner):\n",
    "        qbots[key] = bot\n",
    "    elif isinstance(bot, models.answerer.Answerer):\n",
    "        abots[key] = bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/experiments/exp16.0.2.0.0/qbot_ep_20.vd\n",
      "Loading qbot from data/experiments/exp16.0.2.0.0/qbot_ep_20.vd\n",
      "data/experiments/exp16.0.2.0.0/abot_ep_20.vd\n",
      "Loading abot from data/experiments/exp16.0.2.0.0/abot_ep_20.vd\n"
     ]
    }
   ],
   "source": [
    "qbots = {}\n",
    "abots = {}\n",
    "\n",
    "#load('exp13.0.1.1.1', epoch=19)\n",
    "#load('exp6.0', epoch=65, agent='abot')\n",
    "\n",
    "# pool \"2 random\"\n",
    "pool_size = 2\n",
    "qexp = aexp = 'exp16.0.2.0.0'\n",
    "load(qexp, epoch=20, agent='qbot')\n",
    "load(aexp, epoch=20, agent='abot')\n",
    "\n",
    "#pool_size = 2\n",
    "#load('exp13.0.1.1.1', epoch=28, agent='qbot')\n",
    "#load('exp6.0', epoch=65, agent='abot')\n",
    "\n",
    "# pool \"4 random\"\n",
    "#pool_size = 4\n",
    "#load('exp14.4.1.2.0', epoch=19, agent='qbot')\n",
    "#load('exp14.4.1.2.0', epoch=19, agent='abot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataloader loading json file: data/v2_vqa_info.json\n",
      "\n",
      "Loading the pool\n",
      "number of answer candidates: 3129\n",
      "\n",
      "Dataloader loading Ques file: data/v2_vqa_data.h5\n",
      "Vocab size with <START>, <END>: 5994\n",
      "Dataloader loading h5 file: data/img_bottom_up.h5\n"
     ]
    }
   ],
   "source": [
    "dataset = misc.dataloader.VQADataset({\n",
    "    'inputImg': 'data/img_bottom_up.h5',\n",
    "    'inputQues': 'data/v2_vqa_data.h5',\n",
    "    'inputJson': 'data/v2_vqa_info.json',\n",
    "    'poolType': 'random', # e.g., contrast, random\n",
    "    'poolSize': pool_size,\n",
    "    'randQues': True,\n",
    "}, ['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.split = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "     dataset,\n",
    "     batch_size=20,\n",
    "     shuffle=False,\n",
    "     num_workers=0,\n",
    "     drop_last=True,\n",
    "     pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dliter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = next(dliter)\n",
    "\n",
    "batch = {key: v.cuda() if hasattr(v, 'cuda') \\\n",
    "                                    else v for key, v in batch.items()}\n",
    "\n",
    "gt_ques_str = [q[0].strip('<START> ').strip(' <END>')\n",
    "               for q in utils.old_idx_to_str(dataset.ind2word, batch['ques'], batch['ques_len'], \n",
    "                                         batch['img_id_pool'], 0, [])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent variable visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/z_vis.html') as f:\n",
    "    template = Template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp16.0.2.0.0 None ('greedy', 'greedy') gumbelst-vae\n",
      "exp16.0.2.0.0 None ('greedy', 'sample') gumbelst-vae\n",
      "exp16.0.2.0.0 None ('sample', 'greedy') gumbelst-vae\n",
      "exp16.0.2.0.0 None ('sample', 'sample') gumbelst-vae\n",
      "exp16.0.2.0.0 policy ('greedy', 'greedy') gumbelst-vae\n",
      "exp16.0.2.0.0 policy ('greedy', 'sample') gumbelst-vae\n",
      "exp16.0.2.0.0 policy ('sample', 'greedy') gumbelst-vae\n",
      "exp16.0.2.0.0 policy ('sample', 'sample') gumbelst-vae\n",
      "exp16.0.2.0.0 manual ('interp', 'greedy') gumbelst-vae\n"
     ]
    }
   ],
   "source": [
    "qd = {}\n",
    "#inferences = [('greedy', 'greedy'), ('greedy', 'sample'), ('sample', 'greedy'), ('sample', 'sample')]\n",
    "inferences = [('greedy', 'greedy'), ('greedy', 'sample'), ('sample', 'greedy'), ('sample', 'sample')]\n",
    "# NOTE: manual must be after None because it uses the results of None\n",
    "zsources = [None, 'policy'] #'prior', \n",
    "#zsources += ['manual{}'.format(dim) for dim in list(range(128))[:3]]\n",
    "zsources += ['interpolate']\n",
    "for qk in qbots:\n",
    "    qbot = qbots[qk]\n",
    "    for zkind in zsources:\n",
    "        for inference in inferences:\n",
    "            if zkind is not None and zkind[:6] == 'manual':\n",
    "                if inference != ('sample', 'greedy'):\n",
    "                    continue\n",
    "                inference = ('manual', 'greedy')\n",
    "                newz = vis.single_dim_manual_z(qd[(qk, None) + ('greedy', 'greedy')][1], qbot, dim=int(zkind[6:]))\n",
    "                nsamples = len(newz)\n",
    "            elif zkind == 'interpolate':\n",
    "                if inference != ('sample', 'greedy'):\n",
    "                    continue\n",
    "                zkind = 'manual'\n",
    "                inference = ('interp', 'greedy')\n",
    "                newz = vis.interp_manual_z(qd[(qk, None) + ('greedy', 'greedy')][1])\n",
    "                nsamples = len(newz)\n",
    "            elif inference == ('greedy', 'greedy'):\n",
    "                newz = None\n",
    "                nsamples = 1\n",
    "            else:\n",
    "                newz = None\n",
    "                nsamples = 3\n",
    "            print(qk, zkind, inference, qbot.vaeMode)\n",
    "            qd[(qk, zkind) + inference] = vis.get_questions(batch, qbot, zkind, inference, dataset.ind2word, nsamples=nsamples, manualz=newz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_column(qbot, questions, latents, k, exi, inference, collapse=False):\n",
    "    ztype = k[1] if inference[0] == 'manual' else inference[0]\n",
    "    dectype = inference[1]\n",
    "    result = '<br><b>z-{}, dec-{}:</b><br>'.format(ztype, dectype)\n",
    "    prev_question = ''\n",
    "    prev_sample_i = 0\n",
    "    for sample_i in range(len(questions)):\n",
    "        new_question = questions[sample_i][exi]\n",
    "        if collapse and new_question == prev_question:\n",
    "            continue\n",
    "        result += new_question + '<br>'\n",
    "        if sample_i == 0:\n",
    "            result += '(z=' + latents[sample_i][exi][0]\n",
    "        else:\n",
    "            curr_z = latents[sample_i][exi][1]\n",
    "            prev_z = latents[prev_sample_i][exi][1]\n",
    "            _, curr_idx = curr_z.reshape(qbot.num_vars, -1).max(dim=1)\n",
    "            _, prev_idx = prev_z.reshape(qbot.num_vars, -1).max(dim=1)\n",
    "            change_idxs = (curr_idx - prev_idx).nonzero().reshape(-1).tolist()\n",
    "            result += '(zdiff=' + str(change_idxs)\n",
    "            result += ')<br>'\n",
    "            result += '(z=' + latents[sample_i][exi][0]\n",
    "        result += ')<br>'\n",
    "        prev_question = new_question\n",
    "        prev_sample_i = sample_i\n",
    "    return result                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inferences = inferences + [('manual', 'greedy')]\n",
    "inferences = [('greedy', 'greedy'), ('sample', 'greedy'), ('manual', 'greedy'), ('interp', 'greedy')]\n",
    "def render_partial_key(k, exi):\n",
    "    ques = ''\n",
    "    for inference in inferences:\n",
    "        if k + inference not in qd:\n",
    "            continue\n",
    "        qbot = qbots[k[0]]\n",
    "        questions = qd[k + inference][0]\n",
    "        latents = qd[k + inference][1]\n",
    "        ques += render_column(qbot, questions, latents, k, exi, inference, collapse=(inference[0] == 'interp'))\n",
    "    return ques\n",
    "\n",
    "keys = sum([\n",
    "    #[(k, 'prior') for k in qbots],\n",
    "    [(k, 'policy') for k in qbots],\n",
    "    [(k, None) for k in qbots],\n",
    "] + [\n",
    "    [(k, zs) for k in qbots] for zs in zsources if zs is not None and 'manual' in zs\n",
    "] + [\n",
    "    [(k, 'manual') for k in qbots] for zs in zsources if zs == 'interpolate'\n",
    "], [])\n",
    "\n",
    "examples = []\n",
    "display_data = {\n",
    "    'keys': keys,\n",
    "    'examples': examples,\n",
    "}\n",
    "\n",
    "for exi in range(len(batch['img_id_pool'])):\n",
    "    #(qboti, inference, zkind) = k\n",
    "\n",
    "    img_paths = [vis.load_image(batch['img_id_pool'][exi][i].item())[1] for i in range(batch['img_id_pool'].shape[1])]\n",
    "    example = {\n",
    "            'gt_ques': gt_ques_str[exi],\n",
    "            'img_uris': [vis.img_to_datauri(img_path) for img_path in img_paths],\n",
    "            'questions': [render_partial_key(k, exi) for k in keys],\n",
    "        }\n",
    "    \n",
    "    examples.append(example)\n",
    "\n",
    "html = template.render(display_data)\n",
    "with open('examples.html', 'w') as f:\n",
    "    f.write(html)\n",
    "#display(HTML(html), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/dialog_viz.html') as f:\n",
    "    dialog_template = Template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n"
     ]
    }
   ],
   "source": [
    "wrap_period = 4\n",
    "numRounds = 5\n",
    "qBot = qbots[qexp]\n",
    "aBot = abots[aexp] # or exp6.0\n",
    "z_inference = 'sample'\n",
    "batch_size = batch['img_pool'].shape[0]\n",
    "pool_size = batch['img_id_pool'].shape[1]\n",
    "ans2label = dataset.ans2label\n",
    "label2ans = {label: ans for ans, label in ans2label.items()}\n",
    "assert len(ans2label) == len(label2ans)\n",
    "\n",
    "rounds = []\n",
    "\n",
    "qBot.reset()\n",
    "# observe the image\n",
    "qBot.observe(images=batch['img_pool'])\n",
    "qBot.tracking = True\n",
    "\n",
    "for Round in range(numRounds):\n",
    "    print('Round {}'.format(Round))\n",
    "    if Round == 0:\n",
    "        # observe initial question\n",
    "        qBot.observe(start_question=True)\n",
    "        # since we only has 1 round.\n",
    "        qBot.observe(start_answer=True)\n",
    "\n",
    "    # decode the question\n",
    "    ques, ques_len, stop_logits, _ = qBot.forwardDecode(dec_inference='sample',\n",
    "                                            z_inference=z_inference, z_source='policy')\n",
    "\n",
    "    region_attn = qBot.ctx_coder.region_attn.squeeze(3)\n",
    "    region_uris = vis.region_att_images(batch['img_id_pool'], region_attn,  batch['img_pool_spatial'])\n",
    "    img_attn = qBot.ctx_coder.img_attn.squeeze(2)\n",
    "    pool_uris = vis.pool_atten_uris(img_attn, wrap_period=wrap_period)\n",
    "\n",
    "    logit = qBot.predictImage()\n",
    "    #loss += ce_criterion(logit.squeeze(2), batch['target_pool'].view(-1))\n",
    "    _, predict = torch.max(logit.squeeze(2), dim=1)\n",
    "    predCorrect = (predict == batch['target_pool'].view(-1)).to(torch.float)\n",
    "    \n",
    "    predict_region_attn = qBot.predict_ctx.attn.squeeze(3)\n",
    "    predict_region_uris = vis.region_att_images(batch['img_id_pool'], predict_region_attn,  batch['img_pool_spatial'])\n",
    "    predict_probs = F.softmax(logit.squeeze(2), dim=1)\n",
    "    predict_uris = vis.pool_atten_uris(predict_probs, wrap_period=wrap_period)\n",
    "\n",
    "\n",
    "    # observe the question here.\n",
    "    qBot.observe(ques=ques, ques_len=ques_len, gt_ques=False)\n",
    "    # answer the question here.\n",
    "    ans, rel_logit = aBot.forward(batch['target_image'], ques, ques_len, inference_mode=False)\n",
    "    _, ansIdx = torch.max(ans, dim=1)\n",
    "    # to predict the target image, use the latest latent state and the predict answer to select the target images.\n",
    "    qBot.observe(ans=ansIdx)\n",
    "\n",
    "    rel_probs = F.softmax(rel_logit, dim=1)[:, 1].tolist()\n",
    "    rel_uris = vis.pool_atten_uris(F.softmax(rel_logit, dim=1)[:, 1:2], wrap_period=wrap_period)\n",
    "    \n",
    "    gen_ques_str = utils.old_idx_to_str(dataset.ind2word, ques, ques_len, batch['img_id_pool'], 0, [])\n",
    "    gen_ques_str = [q[0].strip('<START> ').strip(' <END>') for q in gen_ques_str]\n",
    "    \n",
    "    rounds.append({\n",
    "        'questions': gen_ques_str,\n",
    "        'answers': [label2ans[i] for i in ansIdx.tolist()],\n",
    "        'preds': predict.tolist(),\n",
    "        'region_uris': region_uris,\n",
    "        'pool_atten_uris': pool_uris,\n",
    "        'predict_region_uris': predict_region_uris,\n",
    "        'predict_uris': predict_uris,\n",
    "        'is_rel_probs': rel_probs,\n",
    "        'rel_uris': rel_uris,\n",
    "    })\n",
    "\n",
    "    #RoundAccuracy[Round] = float(predCorrect.mean())\n",
    "    #accuracy += float((predCorrect).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "target_idxs = batch['target_pool'].view(-1).tolist()\n",
    "# when displaying a pool, put this many images on one row then wrap to the next row\n",
    "\n",
    "for exi in range(batch_size):\n",
    "    img_paths = []\n",
    "    for i in range(pool_size):\n",
    "        img_idx = batch['img_id_pool'][exi][i].item()\n",
    "        assert img_idx != 0\n",
    "        img_path = vis.load_image(img_idx)[1]\n",
    "        img_paths.append(img_path)\n",
    "    \n",
    "    example = {\n",
    "        'gt_ques': gt_ques_str[exi],\n",
    "        'target': target_idxs[exi],\n",
    "        'img_uris': [vis.img_to_datauri(img_path) for img_path in img_paths],\n",
    "    }\n",
    "    \n",
    "    examples.append(example)\n",
    "\n",
    "html = dialog_template.render({\n",
    "    'title': 'qbot {}, abot {}'.format(qexp, aexp),\n",
    "    'examples': examples,\n",
    "    'rounds': rounds,\n",
    "    'wrap_period': wrap_period,\n",
    "})\n",
    "with open('dialog_examples.html', 'w') as f:\n",
    "    f.write(html)\n",
    "#display(HTML(html), metadata=dict(isolated=True))\n",
    "#display(HTML('<img src=\"{}\"></img>'.format(uri)), metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
